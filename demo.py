"""
digital_steward/demo.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Live Gradio demo for the hackathon presentation.

Shows:
  â€¢ Real-time webcam or video file input
  â€¢ Annotated output frame with VIOLATION / CLEAR banner
  â€¢ Contact patch breakdown per tire (FL/FR/RL/RR)
  â€¢ FastF1 regulatory match panel
  â€¢ Live FPS counter (targeting 60 FPS on GB10)

Run
â”€â”€â”€
  python demo.py
  python demo.py --video path/to/race_clip.mp4
  python demo.py --year 2024 --event Bahrain --session Q
"""

from __future__ import annotations

import argparse
import time
from pathlib import Path
from typing import Optional, Tuple

import cv2
import gradio as gr
import numpy as np
import pandas as pd
import torch
from loguru import logger

from inference.engine import DigitalStewardEngine
from inference.geometry import HomographyCalibrator
from api.fastf1_validator import (
    AIViolationEvent,
    RegulatoryFilter,
    F1SessionData,
    VerdictCategory,
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Global engine (initialised lazily on first use)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_engine: Optional[DigitalStewardEngine] = None
_f1_session: Optional[F1SessionData] = None
_reg_filter: Optional[RegulatoryFilter] = None
_violation_log: list = []


def _get_engine(vit_path: str, yolo_path: str) -> DigitalStewardEngine:
    global _engine
    if _engine is None:
        logger.info("Initialising DigitalStewardEngine for demo ...")
        cal = HomographyCalibrator.default_circuit_points()
        _engine = DigitalStewardEngine(
            vit_fpn_path=vit_path,
            yolo_path=yolo_path,
            calibrator=cal,
            amp=torch.cuda.is_available(),
            use_trt=False,   # set True when TRT engine is exported
        )
    return _engine


def _load_f1_session(year: int, event: str, session: str):
    global _f1_session, _reg_filter
    try:
        _f1_session = F1SessionData(year, event, session).load()
        _reg_filter = RegulatoryFilter(_f1_session, confidence_threshold=0.80)
        return f"âœ… Loaded {year} {event} {session} â€” {_f1_session.deleted_lap_count} deleted laps"
    except Exception as e:
        return f"âš ï¸ Could not load session: {e}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Core processing function (called by Gradio)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_frame_demo(
    frame_rgb: np.ndarray,
    vit_path: str = "models/best_model.pt",
    yolo_path: str = "yolov8n-seg.pt",
    driver_number: int = 1,
    lap_number: int = 1,
) -> Tuple[np.ndarray, str, pd.DataFrame, str]:
    """
    Called by Gradio on each input frame.

    Returns
    â”€â”€â”€â”€â”€â”€â”€
    (annotated_frame_rgb, verdict_text, tire_table_df, fastf1_status)
    """
    if frame_rgb is None:
        blank = np.zeros((720, 1280, 3), dtype=np.uint8)
        return blank, "No frame", pd.DataFrame(), "â€”"

    engine = _get_engine(vit_path, yolo_path)

    # Gradio passes RGB; engine expects BGR
    frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
    result = engine.process_frame(frame_bgr, debug=False)

    # â”€â”€ Annotated frame (back to RGB for Gradio) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    annotated_rgb = cv2.cvtColor(result["annotated"], cv2.COLOR_BGR2RGB)

    # â”€â”€ Verdict text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fps   = result["fps"]
    conf  = result["confidence"]
    viol  = result["violation"]

    verdict_lines = [
        f"{'ğŸš¨ VIOLATION' if viol else 'âœ… CLEAR'}",
        f"Confidence : {conf*100:.1f}%",
        f"FPS        : {fps:.1f}",
    ]
    if result["verdict"] and result["verdict"].note:
        verdict_lines.append(result["verdict"].note)
    verdict_text = "\n".join(verdict_lines)

    # â”€â”€ Tire breakdown table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tire_rows = []
    if result["verdict"] and result["verdict"].patches:
        for p in result["verdict"].patches:
            status = "OUT âŒ" if p.is_fully_out else ("ON LINE âš ï¸" if p.on_line_pixel_count > 0 else "IN âœ…")
            tire_rows.append({
                "Tire": p.name,
                "Inside px": p.inside_pixel_count,
                "On-line px": p.on_line_pixel_count,
                "Outside px": p.out_pixel_count,
                "Status": status,
            })
    tire_df = pd.DataFrame(tire_rows) if tire_rows else pd.DataFrame(
        columns=["Tire", "Inside px", "On-line px", "Outside px", "Status"]
    )

    # â”€â”€ FastF1 regulatory status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ff1_status = "Session not loaded."
    if _reg_filter is not None and viol and conf >= 0.80:
        event = AIViolationEvent(
            driver_number=driver_number,
            lap_number=lap_number,
            timestamp_s=time.time(),
            ai_confidence=conf,
        )
        match = _reg_filter.classify(event)
        ff1_status = f"{match.emoji()}\n{match.note}"
        _violation_log.append(match)

    return annotated_rgb, verdict_text, tire_df, ff1_status


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gradio UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_ui() -> gr.Blocks:
    with gr.Blocks(
        title="Digital Steward â€” F1 Track Limit AI",
        theme=gr.themes.Base(
            primary_hue="red",
            neutral_hue="slate",
            font=gr.themes.GoogleFont("Inter"),
        ),
        css="""
        .verdict-box { font-size: 1.4em; font-family: monospace; }
        .header { background: linear-gradient(90deg, #e10600 0%, #1a1a2e 100%);
                  padding: 20px; border-radius: 8px; }
        """,
    ) as demo:

        gr.HTML("""
        <div class='header'>
          <h1 style='color:white; margin:0; font-size:2em;'>
            ğŸ Digital Steward
          </h1>
          <p style='color:#ccc; margin:4px 0 0 0;'>
            Real-time F1 Track Limit Violation Detector Â· Dell Pro Max GB10 Â· NVIDIA Blackwell
          </p>
        </div>
        """)

        with gr.Row():
            # â”€â”€ Left column: inputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¥ Input")
                cam_input = gr.Image(
                    label="Live Camera / Upload Frame",
                    sources=["webcam", "upload"],
                    type="numpy",
                    streaming=True,
                )
                with gr.Accordion("âš™ï¸ Model Paths", open=False):
                    vit_path = gr.Textbox(
                        value="models/best_model.pt",
                        label="ViT-FPN weights",
                    )
                    yolo_path = gr.Textbox(
                        value="yolov8n-seg.pt",
                        label="YOLOv8-seg weights",
                    )

                gr.Markdown("### ğŸ“¡ FastF1 Session")
                with gr.Row():
                    yr_box    = gr.Number(value=2024, label="Year",    precision=0)
                    ev_box    = gr.Textbox(value="Bahrain", label="Event")
                    ses_box   = gr.Textbox(value="Q", label="Session")
                load_btn  = gr.Button("Load Session", variant="secondary")
                ses_status = gr.Textbox(label="Session Status", interactive=False)
                load_btn.click(
                    fn=lambda y, e, s: _load_f1_session(int(y), e, s),
                    inputs=[yr_box, ev_box, ses_box],
                    outputs=ses_status,
                )

                with gr.Row():
                    drv_box = gr.Number(value=1, label="Driver #", precision=0)
                    lap_box = gr.Number(value=1, label="Lap #",    precision=0)

            # â”€â”€ Right column: outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“Š Steward Output")
                annotated_out = gr.Image(label="Annotated Frame", type="numpy")

                with gr.Row():
                    verdict_out = gr.Textbox(
                        label="Verdict", lines=5,
                        elem_classes=["verdict-box"],
                    )
                    ff1_out = gr.Textbox(
                        label="Regulatory Status (FastF1)", lines=5,
                    )

                tire_table = gr.Dataframe(
                    label="Contact Patch Analysis",
                    headers=["Tire", "Inside px", "On-line px", "Outside px", "Status"],
                )

        # â”€â”€ Streaming connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cam_input.stream(
            fn=process_frame_demo,
            inputs=[cam_input, vit_path, yolo_path, drv_box, lap_box],
            outputs=[annotated_out, verdict_out, tire_table, ff1_out],
        )

        gr.Markdown("""
        ---
        **How it works:**
        1. **YOLOv8-seg** segments Track vs Out-of-Bounds zones in real time.
        2. **ViT-B/16 + FPN** detects the car and white track-limit line.
        3. **Homography** warps the broadcast view to a bird's-eye map.
        4. **Contact Patch Analysis** counts pixels per tire relative to the line.
        5. **FastF1 API** cross-validates AI decisions against FIA timing documents.

        Violation = all four tires have zero pixels on the track side of the white line.
        """)

    return demo


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--year",    type=int,   default=2024)
    parser.add_argument("--event",   type=str,   default="Bahrain")
    parser.add_argument("--session", type=str,   default="Q")
    parser.add_argument("--port",    type=int,   default=7860)
    parser.add_argument("--share",   action="store_true")
    args = parser.parse_args()

    # Pre-load FastF1 if args given
    if args.year and args.event:
        _load_f1_session(args.year, args.event, args.session)

    ui = build_ui()
    ui.launch(
        server_port=args.port,
        share=args.share,
        show_api=False,
    )


if __name__ == "__main__":
    main()
